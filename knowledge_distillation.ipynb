{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing dataset...\n",
      "\n",
      "+------------+-------------------------+------------------------+\n",
      "| Tool       |   Training Images Moved |   Testing Images Moved |\n",
      "+============+=========================+========================+\n",
      "| bottle     |                     209 |                     20 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| cable      |                     224 |                     58 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| capsule    |                     219 |                     23 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| carpet     |                     280 |                     28 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| grid       |                     264 |                     21 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| hazelnut   |                     391 |                     40 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| leather    |                     245 |                     32 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| metal_nut  |                     220 |                     22 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| pill       |                     267 |                     26 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| screw      |                     320 |                     41 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| tile       |                     230 |                     33 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| toothbrush |                      60 |                     12 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| transistor |                     213 |                     60 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| wood       |                     247 |                     19 |\n",
      "+------------+-------------------------+------------------------+\n",
      "| zipper     |                     240 |                     32 |\n",
      "+------------+-------------------------+------------------------+\n",
      "\n",
      "Class-to-Index Mapping:\n",
      "{'bottle': 0, 'cable': 1, 'capsule': 2, 'carpet': 3, 'grid': 4, 'hazelnut': 5, 'leather': 6, 'metal_nut': 7, 'pill': 8, 'screw': 9, 'tile': 10, 'toothbrush': 11, 'transistor': 12, 'wood': 13, 'zipper': 14}\n",
      "\n",
      "Verification of Dataset Integrity:\n",
      "+-----------+--------------------------+---------------------+\n",
      "| Dataset   | Class-to-Index Matches   | Class Names Match   |\n",
      "+===========+==========================+=====================+\n",
      "| Training  | True                     | True                |\n",
      "+-----------+--------------------------+---------------------+\n",
      "| Test      | True                     | True                |\n",
      "+-----------+--------------------------+---------------------+\n",
      "\n",
      "Dataset Statistics:\n",
      "+------------+-----------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Dataset    |   Total Samples | Class Distribution                                                                                                           |\n",
      "+============+=================+==============================================================================================================================+\n",
      "| Training   |            2903 | {5: 313, 4: 211, 3: 224, 6: 196, 9: 256, 12: 170, 1: 179, 14: 192, 0: 167, 13: 198, 10: 184, 11: 48, 7: 176, 8: 214, 2: 175} |\n",
      "+------------+-----------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Validation |             726 | {2: 44, 0: 42, 12: 43, 5: 78, 3: 56, 6: 49, 9: 64, 10: 46, 8: 53, 4: 53, 7: 44, 1: 45, 13: 49, 14: 48, 11: 12}               |\n",
      "+------------+-----------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Test       |             467 | {0: 20, 1: 58, 2: 23, 3: 28, 4: 21, 5: 40, 6: 32, 7: 22, 8: 26, 9: 41, 10: 33, 11: 12, 12: 60, 13: 19, 14: 32}               |\n",
      "+------------+-----------------+------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from mvtec import trainloader, valloader, testloader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check current device: \n",
      "Using GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "print(\"Check current device: \")\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # Should return True \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # Should show your GPU name\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model classes\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper neural network class to be used as teacher:\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Lightweight neural network class to be used as student:\n",
    "class LightNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy runs\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, valloader, epochs, learning_rate, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Training Step\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(trainloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss}\")\n",
    "\n",
    "        # Validation Step\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for inputs, labels in valloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() \n",
    "\n",
    "        avg_val_loss = val_loss / len(valloader)  # Average validation loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "    return train_losses, val_losses \n",
    "\n",
    "def test(model, testloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\t\n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics using sklearn\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    report = classification_report(all_labels, all_predictions, output_dict=True)\n",
    "\n",
    "    return cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate the teacher model.\n",
      "Instantiate the student model.\n",
      "Cross-entropy runs with teacher model: \n",
      "Epoch 1/10, Loss: 0.8543916850627123\n",
      "Epoch 1/10, Validation Loss: 0.2153\n",
      "Epoch 2/10, Loss: 0.13018769514874892\n",
      "Epoch 2/10, Validation Loss: 0.0626\n",
      "Epoch 3/10, Loss: 0.10132275553737449\n",
      "Epoch 3/10, Validation Loss: 0.0194\n",
      "Epoch 4/10, Loss: 0.15161932234212264\n",
      "Epoch 4/10, Validation Loss: 0.1645\n",
      "Epoch 5/10, Loss: 0.07519371557586114\n",
      "Epoch 5/10, Validation Loss: 0.0140\n",
      "Epoch 6/10, Loss: 0.07865646353441132\n",
      "Epoch 6/10, Validation Loss: 0.0075\n",
      "Epoch 7/10, Loss: 0.11695599872505377\n",
      "Epoch 7/10, Validation Loss: 0.0027\n",
      "Epoch 8/10, Loss: 0.20637845634713073\n",
      "Epoch 8/10, Validation Loss: 0.1525\n",
      "Epoch 9/10, Loss: 0.055682318177007674\n",
      "Epoch 9/10, Validation Loss: 0.0036\n",
      "Epoch 10/10, Loss: 0.015856104381177977\n",
      "Epoch 10/10, Validation Loss: 0.0175\n",
      "Teacher Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Instantiate the teacher model.\")\n",
    "torch.manual_seed(42)\n",
    "nn_deep = DeepNN(num_classes=15).to(device)\n",
    "print(\"Instantiate the student model.\")\n",
    "torch.manual_seed(42)\n",
    "nn_light = LightNN(num_classes=15).to(device)\n",
    "print(\"Cross-entropy runs with teacher model: \")\n",
    "train_deep = train(nn_deep, trainloader, valloader, epochs=10, learning_rate=0.001, device=device)\n",
    "test_deep = test(nn_deep, testloader, device)\n",
    "test_accuracy_deep = test_deep[1][\"accuracy\"] * 100\n",
    "print(f\"Teacher Accuracy: {test_accuracy_deep:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate a copy of the student model.\n",
      "######################################################################\n",
      "To ensure we have created a copy of the student network, we inspect the norm of its first layer.\n",
      "If it matches, then we are safe to conclude that the networks are indeed the same.\n",
      "Norm of 1st layer of nn_light: 2.327361822128296\n",
      "Norm of 1st layer of new_nn_light: 2.320908784866333\n",
      "######################################################################\n",
      "The total number of parameters in each model\n",
      "Teacher model parameters: 51,521,199\n",
      "Student model parameters: 25,696,991\n",
      "\n",
      "######################################################################\n",
      "Cross-entropy runs with student model: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x50176 and 100352x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m######################################################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-entropy runs with student model: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m train_light_ce \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_light\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m test_light_ce \u001b[38;5;241m=\u001b[39m test(nn_light, testloader, device)\n\u001b[0;32m     23\u001b[0m test_accuracy_light_ce \u001b[38;5;241m=\u001b[39m test_light_ce[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, valloader, epochs, learning_rate, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 52\u001b[0m, in \u001b[0;36mLightNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Arcade Projects\\Knowledge_Distillation_Testing\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x50176 and 100352x256)"
     ]
    }
   ],
   "source": [
    "print(\"Instantiate a copy of the student model.\")\n",
    "new_nn_light = LightNN(num_classes=15).to(device)\n",
    "print(\"######################################################################\")\n",
    "\n",
    "# Print the norm of the first layer of the initial lightweight model\n",
    "print(\"To ensure we have created a copy of the student network, we inspect the norm of its first layer.\")\n",
    "print(\"If it matches, then we are safe to conclude that the networks are indeed the same.\")\n",
    "print(\"Norm of 1st layer of nn_light:\", torch.norm(nn_light.features[0].weight).item())\n",
    "print(\"Norm of 1st layer of new_nn_light:\", torch.norm(new_nn_light.features[0].weight).item())\n",
    "\n",
    "print(\"######################################################################\")\n",
    "print(\"The total number of parameters in each model\")\n",
    "total_params_deep = \"{:,}\".format(sum(p.numel() for p in nn_deep.parameters()))\n",
    "print(f\"Teacher model parameters: {total_params_deep}\")\n",
    "total_params_light = \"{:,}\".format(sum(p.numel() for p in nn_light.parameters()))\n",
    "print(f\"Student model parameters: {total_params_light}\")\n",
    "\n",
    "print()\n",
    "print(\"######################################################################\")\n",
    "print(\"Cross-entropy runs with student model: \")\n",
    "train_light_ce = train(nn_light, trainloader, valloader, epochs=10, learning_rate=0.001, device=device)\n",
    "test_light_ce = test(nn_light, testloader, device)\n",
    "test_accuracy_light_ce = test_light_ce[1][\"accuracy\"] * 100\n",
    "print(f\"Student Accuracy: {test_accuracy_light_ce:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge distillation run\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(teacher, student, trainloader, valloader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "    student.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(trainloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss}\")\n",
    "\n",
    "        # Validation Step\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for inputs, labels in valloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = ce_loss(outputs, labels)\n",
    "                val_loss += loss.item() \n",
    "\n",
    "        avg_val_loss = val_loss / len(valloader)  # Average validation loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "    return train_losses, val_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-entropy runs with the copy of the student model: \")\n",
    "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "train_light_ce_and_kd = train_knowledge_distillation(teacher=nn_deep, student=new_nn_light, train_loader=trainloader, val_loader=valloader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_light_ce_and_kd = test(new_nn_light, testloader, device)\n",
    "test_accuracy_light_ce_and_kd = test_light_ce_and_kd[1][\"accuracy\"] * 100\n",
    "precision_light_ce_and_kd = test_light_ce_and_kd[1][\"weighted avg\"][\"precision\"]\n",
    "recall_light_ce_and_kd = test_light_ce_and_kd[1][\"weighted avg\"][\"recall\"]\n",
    "f1_light_ce_and_kd = test_light_ce_and_kd[1][\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Student accuracy with CE + KD:\")\n",
    "print(f\"Accuracy: {test_accuracy_light_ce_and_kd:.2f}%\")\n",
    "# Print other value metrics:\n",
    "print(f\"Precision: {precision_light_ce_and_kd:.2f}\")\n",
    "print(f\"Recall: {recall_light_ce_and_kd:.2f}\")\n",
    "print(f\"F1 Score: {f1_light_ce_and_kd:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle(\"Training and Validation Loss of Student model\", fontsize=16)\n",
    "\n",
    "# Visualize the loss scores of student model - ce\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 11), train_light_ce[0], label=\"Train Loss\")\n",
    "plt.plot(range(1, 11), train_light_ce[1], label=\"Validation Loss\")\n",
    "plt.axhline(y=test_accuracy_light_ce, color='red', linestyle='--', label='Test Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('with Cross-Entropy')\n",
    "\n",
    "# Visualize the loss scores of student model - ce + kd\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 11), train_light_ce_and_kd[0], label=\"Train Loss\")\n",
    "plt.plot(range(1, 11), train_light_ce_and_kd[1], label=\"Validation Loss\")\n",
    "plt.axhline(y=test_accuracy_light_ce_and_kd, color='red', linestyle='--', label='Test Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('with Knowledge Distillation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = test_light_ce_and_kd[0]\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(24, 24)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, colorbar=False)\n",
    "plt.title(\"Confusion Matrix of Student model with Knowledge Distillation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
