{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import cv2 \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "# from kd_export import LightNN\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight neural network class to be used as student:\n",
    "class LightNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 56 * 56, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img): \n",
    "  \n",
    "    # Getting the dimensions of the image \n",
    "    row , col = img.shape \n",
    "      \n",
    "    # Randomly pick some pixels in the \n",
    "    # image for coloring them white \n",
    "    # Pick a random number between 300 and 10000 \n",
    "    number_of_pixels = random.randint(300, 10000) \n",
    "    for i in range(number_of_pixels): \n",
    "        \n",
    "        # Pick a random y coordinate \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "          \n",
    "        # Pick a random x coordinate \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "          \n",
    "        # Color that pixel to white \n",
    "        img[y_coord][x_coord] = 255\n",
    "          \n",
    "    # Randomly pick some pixels in \n",
    "    # the image for coloring them black \n",
    "    # Pick a random number between 300 and 10000 \n",
    "    number_of_pixels = random.randint(300 , 10000) \n",
    "    for i in range(number_of_pixels): \n",
    "        \n",
    "        # Pick a random y coordinate \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "          \n",
    "        # Pick a random x coordinate \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "          \n",
    "        # Color that pixel to black \n",
    "        img[y_coord][x_coord] = 0\n",
    "          \n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_origin = \"./mvtec_dataset\"\n",
    "\n",
    "base_dir = \"organized_test\"\n",
    "store_dir = \"noise_test\"\n",
    "\n",
    "test_output_path = os.path.join(base_origin, base_dir)\n",
    "noise_output_path = os.path.join(base_origin, store_dir)\n",
    "\n",
    "os.makedirs(noise_output_path, exist_ok=True)\n",
    "\n",
    "# Dictionary to store images\n",
    "images = {}\n",
    "\n",
    "# Loop through each folder\n",
    "for folder_name in os.listdir(test_output_path):\n",
    "    folder_path = os.path.join(test_output_path, folder_name)\n",
    "    save_path = os.path.join(noise_output_path, folder_name)\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            file_save = os.path.join(save_path, file_name)\n",
    "            \n",
    "            # Check if it's an image file (optional)\n",
    "            if file_name.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                img = cv2.imread(file_path, \n",
    "                                cv2.IMREAD_GRAYSCALE) \n",
    "                \n",
    "                #Storing the image \n",
    "                cv2.imwrite(file_save, \n",
    "                            add_noise(img)) \n",
    "\n",
    "# Close all OpenCV windows (if used)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools\n",
    "tools = [\n",
    "    \"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\", \"hazelnut\", \"leather\", \"metal_nut\",\n",
    "    \"pill\", \"screw\", \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"\n",
    "]\n",
    "\n",
    "classes = sorted(tools)\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "\n",
    "class FixedImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform, class_to_idx):\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.classes = list(class_to_idx.keys())\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        return self.classes, self.class_to_idx\n",
    "    \n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "noise_dataset = FixedImageFolder(\n",
    "    root=noise_output_path,\n",
    "    transform=val_test_transforms,\n",
    "    class_to_idx=class_to_idx\n",
    ")\n",
    "noiseloader = DataLoader(noise_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check current device: \n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Check current device: \")\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # Should return True \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # Should show your GPU name\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"student_model.pth\"\n",
    "pretrained_model_KD = \"student_model_KD.pth\"\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=50176, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "torch.manual_seed(42)\n",
    "model = LightNN(num_classes=15).to(device)\n",
    "torch.manual_seed(42)\n",
    "model_KD = LightNN(num_classes=15).to(device)\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device, weights_only=True))\n",
    "model_KD.load_state_dict(torch.load(pretrained_model_KD, map_location=device, weights_only=True))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "model_KD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, device):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\t\n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics using sklearn\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    report = classification_report(all_labels, all_predictions, output_dict=True, zero_division=0)\n",
    "\n",
    "    return cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Student accuracy with CE + KD:\n",
      "Accuracy: 89.51%\n",
      "Precision: 0.90\n",
      "Recall: 0.90\n",
      "F1 Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run noise dataset for each epsilon\n",
    "test_light_noise = test(model, noiseloader, device)\n",
    "test_accuracy_light_noise = test_light_noise[1][\"accuracy\"] * 100\n",
    "precision_light_noise = test_light_noise[1][\"weighted avg\"][\"precision\"]\n",
    "recall_light_noise = test_light_noise[1][\"weighted avg\"][\"recall\"]\n",
    "f1_light_noise = test_light_noise[1][\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "# print(\"-----------------------------------------\")\n",
    "# print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "# print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Student accuracy with CE + KD:\")\n",
    "print(f\"Accuracy: {test_accuracy_light_noise:.2f}%\")\n",
    "# Print other value metrics:\n",
    "print(f\"Precision: {precision_light_noise:.2f}\")\n",
    "print(f\"Recall: {recall_light_noise:.2f}\")\n",
    "print(f\"F1 Score: {f1_light_noise:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Student accuracy with CE + KD:\n",
      "Accuracy: 88.22%\n",
      "Precision: 0.83\n",
      "Recall: 0.88\n",
      "F1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run noise dataset for each epsilon\n",
    "test_light_noise = test(model_KD, noiseloader, device)\n",
    "test_accuracy_light_noise = test_light_noise[1][\"accuracy\"] * 100\n",
    "precision_light_noise = test_light_noise[1][\"weighted avg\"][\"precision\"]\n",
    "recall_light_noise = test_light_noise[1][\"weighted avg\"][\"recall\"]\n",
    "f1_light_noise = test_light_noise[1][\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "# print(\"-----------------------------------------\")\n",
    "# print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "# print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Student accuracy with CE + KD:\")\n",
    "print(f\"Accuracy: {test_accuracy_light_noise:.2f}%\")\n",
    "# Print other value metrics:\n",
    "print(f\"Precision: {precision_light_noise:.2f}\")\n",
    "print(f\"Recall: {recall_light_noise:.2f}\")\n",
    "print(f\"F1 Score: {f1_light_noise:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
