{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import cv2 \n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from kd_export import LightNN\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img): \n",
    "  \n",
    "    # Getting the dimensions of the image \n",
    "    row , col = img.shape \n",
    "      \n",
    "    # Randomly pick some pixels in the \n",
    "    # image for coloring them white \n",
    "    # Pick a random number between 300 and 10000 \n",
    "    number_of_pixels = random.randint(300, 10000) \n",
    "    for i in range(number_of_pixels): \n",
    "        \n",
    "        # Pick a random y coordinate \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "          \n",
    "        # Pick a random x coordinate \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "          \n",
    "        # Color that pixel to white \n",
    "        img[y_coord][x_coord] = 255\n",
    "          \n",
    "    # Randomly pick some pixels in \n",
    "    # the image for coloring them black \n",
    "    # Pick a random number between 300 and 10000 \n",
    "    number_of_pixels = random.randint(300 , 10000) \n",
    "    for i in range(number_of_pixels): \n",
    "        \n",
    "        # Pick a random y coordinate \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "          \n",
    "        # Pick a random x coordinate \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "          \n",
    "        # Color that pixel to black \n",
    "        img[y_coord][x_coord] = 0\n",
    "          \n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_origin = \"./mvtec_dataset\"\n",
    "\n",
    "base_dir = \"organized_test\"\n",
    "store_dir = \"noise_test\"\n",
    "\n",
    "test_output_path = os.path.join(base_origin, base_dir)\n",
    "noise_output_path = os.path.join(base_origin, store_dir)\n",
    "\n",
    "os.makedirs(noise_output_path, exist_ok=True)\n",
    "\n",
    "# Dictionary to store images\n",
    "images = {}\n",
    "\n",
    "# Loop through each folder\n",
    "for folder_name in os.listdir(test_output_path):\n",
    "    folder_path = os.path.join(test_output_path, folder_name)\n",
    "    save_path = os.path.join(noise_output_path, folder_name)\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            file_save = os.path.join(save_path, file_name)\n",
    "            \n",
    "            # Check if it's an image file (optional)\n",
    "            if file_name.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                img = cv2.imread(file_path, \n",
    "                                cv2.IMREAD_GRAYSCALE) \n",
    "                \n",
    "                #Storing the image \n",
    "                cv2.imwrite(file_save, \n",
    "                            add_noise(img)) \n",
    "\n",
    "# Close all OpenCV windows (if used)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools\n",
    "tools = [\n",
    "    \"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\", \"hazelnut\", \"leather\", \"metal_nut\",\n",
    "    \"pill\", \"screw\", \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"\n",
    "]\n",
    "\n",
    "classes = sorted(tools)\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "\n",
    "class FixedImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform, class_to_idx):\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.classes = list(class_to_idx.keys())\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        return self.classes, self.class_to_idx\n",
    "    \n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "noise_dataset = FixedImageFolder(\n",
    "    root=noise_output_path,\n",
    "    transform=val_test_transforms,\n",
    "    class_to_idx=class_to_idx\n",
    ")\n",
    "noiseloader = DataLoader(noise_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check current device: \")\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # Should return True \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # Should show your GPU name\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"student_model.pth\"\n",
    "pretrained_model_KD = \"student_model_KD.pth\"\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "torch.manual_seed(42)\n",
    "model = LightNN(num_classes=15).to(device)\n",
    "torch.manual_seed(42)\n",
    "model_KD = LightNN(num_classes=15).to(device)\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device, weights_only=True))\n",
    "model_KD.load_state_dict(torch.load(pretrained_model_KD, map_location=device, weights_only=True))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "model_KD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, device, noiseloader, epsilon ):\n",
    "\n",
    "#     # Accuracy counter\n",
    "#     correct = 0\n",
    "#     adv_examples = []\n",
    "\n",
    "#     # Loop over all examples in test set\n",
    "#     for data, target in noiseloader:\n",
    "\n",
    "#         # Send the data and label to the device\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         # Set requires_grad attribute of tensor. Important for Attack\n",
    "#         data.requires_grad = True\n",
    "\n",
    "#         # Forward pass the data through the model\n",
    "#         output = model(data)\n",
    "#         init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "#         # If the initial prediction is wrong, don't bother attacking, just move on\n",
    "#         if init_pred.item() != target.item():\n",
    "#             continue\n",
    "\n",
    "#         # Calculate the loss\n",
    "#         loss = F.nll_loss(output, target)\n",
    "\n",
    "#         # Zero all existing gradients\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Calculate gradients of model in backward pass\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Collect ``datagrad``\n",
    "#         data_grad = data.grad.data\n",
    "\n",
    "#         # Restore the data to its original scale\n",
    "#         data_denorm = denorm(data)\n",
    "\n",
    "#         # Call FGSM Attack\n",
    "#         perturbed_data = fgsm_attack(data_denorm, epsilon, data_grad)\n",
    "\n",
    "#         # Reapply normalization\n",
    "#         perturbed_data_normalized = transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)\n",
    "\n",
    "#         # Re-classify the perturbed image\n",
    "#         output = model(perturbed_data_normalized)\n",
    "\n",
    "#         # Check for success\n",
    "#         final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "#         if final_pred.item() == target.item():\n",
    "#             correct += 1\n",
    "#             # Special case for saving 0 epsilon examples\n",
    "#             if epsilon == 0 and len(adv_examples) < 5:\n",
    "#                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "#                 adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "#         else:\n",
    "#             # Save some adv examples for visualization later\n",
    "#             if len(adv_examples) < 5:\n",
    "#                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "#                 adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "#     # Calculate final accuracy for this epsilon\n",
    "#     final_acc = correct/float(len(noiseloader))\n",
    "#     print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len(noiseloader)} = {final_acc}\")\n",
    "\n",
    "#     # Return the accuracy and an adversarial example\n",
    "#     return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, device):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\t\n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics using sklearn\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    report = classification_report(all_labels, all_predictions, output_dict=True)\n",
    "\n",
    "    return cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run noise dataset for each epsilon\n",
    "test_light_noise = test(model, device, noiseloader, 0.1)\n",
    "test_accuracy_light_noise = test_light_noise[1][\"accuracy\"] * 100\n",
    "precision_light_noise = test_light_noise[1][\"weighted avg\"][\"precision\"]\n",
    "recall_light_noise = test_light_noise[1][\"weighted avg\"][\"recall\"]\n",
    "f1_light_noise = test_light_noise[1][\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "# print(\"-----------------------------------------\")\n",
    "# print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "# print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Student accuracy with CE + KD:\")\n",
    "print(f\"Accuracy: {test_accuracy_light_noise:.2f}%\")\n",
    "# Print other value metrics:\n",
    "print(f\"Precision: {precision_light_noise:.2f}\")\n",
    "print(f\"Recall: {recall_light_noise:.2f}\")\n",
    "print(f\"F1 Score: {f1_light_noise:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = test_light_noise[0]\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
