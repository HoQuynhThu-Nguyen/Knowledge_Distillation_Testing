{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import art.attacks.evasion as toolbox\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from kd_export import LightNN\n",
    "from mvtec import test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check current device: \")\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # Should return True \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # Should show your GPU name\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"student_model.pth\"\n",
    "pretrained_model_KD = \"student_model_KD.pth\"\n",
    "use_cuda=True\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "torch.manual_seed(42)\n",
    "model = LightNN(num_classes=15).to(device)\n",
    "torch.manual_seed(42)\n",
    "model_KD = LightNN(num_classes=15).to(device)\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device, weights_only=True))\n",
    "model_KD.load_state_dict(torch.load(pretrained_model_KD, map_location=device, weights_only=True))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "model_KD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Wrap the model with PyTorchClassifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0, 1),  # Input values range, e.g., for normalized images\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 224, 224),  # Adjust to your input shape\n",
    "    nb_classes=10              # Number of output classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([data[0].numpy() for data in test_dataset])\n",
    "y_test = np.array([data[1] for data in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FGSM attack\n",
    "attack = toolbox.FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_fgsm = attack.generate(x=x_test)\n",
    "\n",
    "# Evaluate accuracy on adversarial examples\n",
    "predictions = classifier.predict(x_test_adv_fgsm)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
    "print(f\"Accuracy on FSGM attack: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PGD attack\n",
    "pgd_attack = toolbox.ProjectedGradientDescent(estimator=classifier, eps=0.1, eps_step=0.01, max_iter=40)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_pgd = pgd_attack.generate(x=x_test)\n",
    "\n",
    "# Evaluate accuracy on adversarial examples\n",
    "predictions = classifier.predict(x_test_adv_pgd)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
    "print(f\"Accuracy on PGD attack: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create C&W attack\n",
    "cw2_attack = toolbox.CarliniL2Method(estimator=classifier, confidence=0.0, max_iter=40, learning_rate=0.01)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_cw2 = cw2_attack.generate(x=x_test)\n",
    "\n",
    "# Evaluate accuracy on adversarial examples\n",
    "predictions = classifier.predict(x_test_adv_cw2)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
    "print(f\"Accuracy on CW2 attack: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Universal Perturbations attack\n",
    "up_attack = toolbox.UniversalPerturbation(estimator=classifier,attacker=\"deepfool\",\n",
    "                                          attacker_params={\"eps\": 0.1},\n",
    "                                          delta=0.2,\n",
    "                                          max_iter=10,\n",
    "                                          eps=0.1,\n",
    "                                          batch_size=32,\n",
    "                                          verbose=True)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_up = up_attack.generate(x=x_test)\n",
    "\n",
    "# Evaluate accuracy on adversarial examples\n",
    "predictions = classifier.predict(x_test_adv_up)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
    "print(f\"Accuracy on UP attack: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Salt-and-Pepper Noise attack\n",
    "up_attack = toolbox\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_up = up_attack.generate(x=x_test)\n",
    "\n",
    "# Evaluate accuracy on adversarial examples\n",
    "predictions = classifier.predict(x_test_adv_up)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
    "print(f\"Accuracy on UP attack: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
