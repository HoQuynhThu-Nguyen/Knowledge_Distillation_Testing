{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import art.attacks.evasion as toolbox\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check current device: \")\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # Should return True\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # Should show your GPU name\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "### set RNG seed\n",
    "RNG_SEED = 0\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "\ttorch.cuda.manual_seed(RNG_SEED)\n",
    "\ttorch.cuda.manual_seed_all(RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "test_image = np.array([data[0].numpy() for data in test_dataset])\n",
    "test_label = np.array([data[1] for data in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_res = 10\n",
    "eps_min = 0.0001\n",
    "eps_max = 0.3\n",
    "\n",
    "# Generating the list of values\n",
    "eps_list = [eps_min + i * (eps_max - eps_min) / (eps_res - 1) for i in range(eps_res)]\n",
    "noise_percents = np.arange(0.0, 0.55, 0.05)  # Noise levels from 0.0 to 0.5\n",
    "\n",
    "files = ['MobileNetV3_large_CE.pth', 'MobileNetV3_small_10_CE.pth', \n",
    "         'KD_model_2_0.pth', 'KD_model_2_1.pth', 'KD_model_2_2.pth', 'KD_model_2_3.pth', 'KD_model_2_4.pth', \n",
    "         'KD_model_3_5.pth', 'KD_model_3_6.pth', 'KD_model_3_7.pth', 'KD_model_3_8.pth', 'KD_model_3_9.pth',\n",
    "         'KD_model_4_10.pth', 'KD_model_4_11.pth', 'KD_model_4_12.pth', 'KD_model_4_13.pth', 'KD_model_4_14.pth',\n",
    "         'KD_model_5_15.pth', 'KD_model_5_16.pth', 'KD_model_5_17.pth', 'KD_model_5_18.pth', 'KD_model_5_19.pth']\n",
    "\n",
    "pgd_all_accuracies = []\n",
    "snp_all_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolbox_generate(eps, classifier, test_image=test_image, test_label=test_label):\n",
    "    pgd_attack = toolbox.ProjectedGradientDescent(estimator=classifier, eps=eps)\n",
    "    x_test_adv_pgd = pgd_attack.generate(x=test_image)\n",
    "    predictions = classifier.predict(x_test_adv_pgd)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == test_label) / len(test_label)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salt-and-Pepper Noise Class (same as corrected version)\n",
    "class SaltAndPepperNoise:\n",
    "    def __init__(self, noise_percent=0.1):\n",
    "        self.noise_percent = noise_percent\n",
    "\n",
    "    def generate(self, xs):\n",
    "        noisy_xs = np.copy(xs)\n",
    "        num_pixels = int(self.noise_percent * xs.size)\n",
    "\n",
    "        # Salt noise\n",
    "        salt_coords = [np.random.randint(0, i, num_pixels // 2) for i in xs.shape]\n",
    "        noisy_xs[tuple(salt_coords)] = 1.0\n",
    "\n",
    "        # Pepper noise\n",
    "        pepper_coords = [np.random.randint(0, i, num_pixels // 2) for i in xs.shape]\n",
    "        noisy_xs[tuple(pepper_coords)] = 0.0\n",
    "\n",
    "        return noisy_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "for f in files:  \n",
    "    if f == 'MobileNetV3_large_CE.pth':\n",
    "      torch.manual_seed(42)\n",
    "      model = models.mobilenet_v3_large(weights=None)\n",
    "    else:\n",
    "      torch.manual_seed(42)\n",
    "      model = models.mobilenet_v3_small(weights=None)\n",
    "\n",
    "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, 10)\n",
    "    model.load_state_dict(torch.load(f, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    classifier_pgd = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3, 224, 224), \n",
    "        nb_classes=10   \n",
    "    )\n",
    "\n",
    "    classifier_snp = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3, 224, 224), \n",
    "        nb_classes=10   \n",
    "    )\n",
    "\n",
    "    pgd_accuracy = []\n",
    "    snp_accuracy = []\n",
    "\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Running PGD......... {f}\")\n",
    "    for eps in eps_list:\n",
    "        accuracy = toolbox_generate(eps, classifier_pgd)\n",
    "        pgd_accuracy.append(accuracy * 100)\n",
    "        print(f\"Accuracy with epsilon {eps}: {accuracy * 100:.2f}%\")\n",
    "    pgd_all_accuracies.append(pgd_accuracy)\n",
    "\n",
    "    print(f\"Running SNP......... {f}\")\n",
    "\n",
    "    # Apply Salt-and-Pepper Noise for each noise level\n",
    "    for noise_percent in noise_percents:\n",
    "        print(f\"\\nEvaluating Salt-and-Pepper Noise with noise_percent = {noise_percent}\")\n",
    "        spn_attack = SaltAndPepperNoise(noise_percent=noise_percent)\n",
    "\n",
    "        # Initialize lists to collect noisy images and labels\n",
    "        noisy_test_images = []\n",
    "        test_labels = []\n",
    "\n",
    "        # Generate noisy images for the entire test set\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Adding Noise (percent={noise_percent})\"):\n",
    "            noisy_images = spn_attack.generate(images.numpy())\n",
    "            noisy_test_images.append(noisy_images)\n",
    "            test_labels.append(labels.numpy())\n",
    "\n",
    "        # Concatenate all noisy examples and labels\n",
    "        noisy_test_images = np.vstack(noisy_test_images)\n",
    "        test_labels = np.hstack(test_labels)\n",
    "\n",
    "        # Predict on noisy examples\n",
    "        preds = np.argmax(classifier_snp.predict(noisy_test_images), axis=1)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(preds == test_labels) * 100\n",
    "        print(f\"Accuracy with noise_percent={noise_percent}: {accuracy:.2f}%\")\n",
    "\n",
    "        # Store the results\n",
    "        snp_accuracy.append(accuracy)\n",
    "    snp_all_accuracies.append(snp_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pgd_all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snp_all_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
